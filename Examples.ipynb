{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba7ed4b4",
   "metadata": {},
   "source": [
    "## Files used in bertFuncs.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e420e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertFuncs import analyzeWord, getBert\n",
    "from createDims import createPolarDimension\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import string\n",
    "import ast\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a9ed2",
   "metadata": {},
   "source": [
    "## Creating the required lookup files\n",
    "\n",
    "The lookup files are needed to set up the POLAR dimensions and to match these dimensions to word sense definitions and example sentences, when analyzing the result.\n",
    "\n",
    "The function ``create_lookup_files`` takes a list of lists as input. Each inner list contains a polar sense pair, where each word sense must be in WordNet readable format e.g. ``cold.a.01``), in orderder to automatically retrieve definitions and example sentences. All lookup files will be stored in the folder ``lookup_path``. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d8e183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_name(antonym):\n",
    "    return wn.synset(antonym).lemma_names()[0]\n",
    "\n",
    "def get_examples(antonym):\n",
    "    examples = wn.synset(antonym).examples()\n",
    "    # replace punctuation symbols with spaces\n",
    "    examples = [sent.translate(str.maketrans({k: \" \" for k in string.punctuation})) for sent in examples]\n",
    "    # add a space after each sentence\n",
    "    return ['{} '.format(sent) for sent in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ab34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookup_files(antonyms, lookup_path):\n",
    "    if len(np.unique(antonyms, axis=0)) != len(antonyms):\n",
    "        print(\"Your antonym list contains duplicates. Please try again!\")\n",
    "        return\n",
    "    \n",
    "    # get all word sense definitions\n",
    "    synset_defs = [[wn.synset(anto).definition() for anto in pair] for pair in antonyms]\n",
    "    # get example sentences from wordnet\n",
    "    examples_readable = {str(pair):{get_name(anto): get_examples(anto) for anto in pair} for pair in antonyms}\n",
    "    examples_lookup = [[[get_name(anto), get_examples(anto)] for anto in pair] for pair in antonyms]\n",
    "    \n",
    "    # save \n",
    "    with open(out_path + 'lookup_synset_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(antonyms, indent=4))\n",
    "    with open(out_path + 'lookup_synset_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(antonyms, p)\n",
    "    with open(lookup_path + 'lookup_synset_definition.txt', 'w') as t:\n",
    "        t.write(json.dumps(synset_defs, indent=4))  \n",
    "    with open(lookup_path + 'lookup_synset_definition.pkl', 'wb') as p:\n",
    "        pickle.dump(synset_defs, p)        \n",
    "    with open(lookup_path + 'antonym_wordnet_example_sentences_readable_extended.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_readable, indent=4))  \n",
    "    with open(lookup_path + 'lookup_anto_example_dict.txt', 'w') as t:\n",
    "        t.write(json.dumps(examples_lookup, indent=4))      \n",
    "    with open(lookup_path + 'lookup_anto_example_dict.pkl', 'wb') as p:\n",
    "        pickle.dump(examples_lookup, p)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2f37b",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e77ad0",
   "metadata": {},
   "source": [
    "Polar dimensions should be __given__ as nested list of antonym pairs in wordnet representation (sense-annotated).\n",
    "\n",
    "_Example:_   \n",
    "`\n",
    "[\n",
    "    ['a_posteriori.a.01', 'a_priori.a.01'],\n",
    "    ['abaxial.a.01', 'adaxial.a.01'],\n",
    "    ['abridge.v.01', 'elaborate.v.01'],\n",
    "    ...\n",
    "]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f200e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder in which all lookup files will be stored\n",
    "out_path = 'antonyms/example/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89588ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 3 exemplary POLAR dimensions\n",
    "dims = [['cold.a.01', 'hot.a.01'], ['bad.a.01', 'good.a.01'], ['intelligent.a.01', 'unintelligent.a.01'], ['capable.a.01', 'incapable.a.01']]\n",
    "    \n",
    "# create all lookup files\n",
    "create_lookup_files(dims, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the embedding model \n",
    "tokenizer, model = getBert()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25e2f2c",
   "metadata": {},
   "source": [
    "Create the POLAR matrix (for base change or projection) from a given set of antonyms. The antonyms and their example sentences are forwarded to an embedding model (here: BERT) from which the required embeddings and difference vectors are created. ``antonym_path`` specifies where the readable example sentence lookup file is currently stored. ``out_path`` specifies where the POLAR matrix should be stored.\n",
    "\n",
    "The corresponding function can be found in ``createDims.py`` which is not part of the official SensePOLAR repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2a4ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the base change matrix (this might take some time)\n",
    "createPolarDimension(model, tokenizer, out_path=out_path, antonym_path=out_path + \"antonym_wordnet_example_sentences_readable_extended.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base change does not work well with only few dimensions -> compare with projection\n",
    "antonym_path = out_path + \"polar_dimensions.pkl\"\n",
    "word = \"school\"\n",
    "context = \"school teaches you a lot of smart things\"\n",
    "analyzeWord(word, context, model=model,tokenizer=tokenizer, antonym_path=antonym_path, lookup_path=out_path, numberPolar=4) #method=\"projection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d81d9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "antonym_path = out_path + \"polar_dimensions.pkl\"\n",
    "word = \"fire\"\n",
    "context = \"the fire is burning\"\n",
    "\n",
    "analyzeWord(word, context, model=model, tokenizer=tokenizer, antonym_path=antonym_path, lookup_path=out_path, numberPolar=4, method=\"projection\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
